from snakemake.utils import validate
from urllib.parse import urlparse
import os
from functools import partial

wildcard_constraints:
    feature_name="[a-zA-Z0-9_]+",
    idx="[0-9]+",


def scale_by_attempt(base_mb):
    def _scale_by_attempt(wildcards, attempt):
        return base_mb*attempt
    return _scale_by_attempt

#configfile: "config.yaml"
validate(config, 'config.schema.yaml')

CORPUS_NAME="{corpus_name}/corpus.h5"
REGIONS_NAME="{corpus_name}/regions.bed"
FEATURE_TYPE_PARAMS = {
    'bigwig' : ['normalization', 'extend', 'group'],
    'bedgraph' : ['normalization', 'extend', 'group'],
    'distance' : ['normalization', 'group'],
    'categorical' : ['null_value', 'column', 'group'],
    'vector' : ['normalization', 'group'],
    'cardinality' : ['column'],
}
TRANSCRIPTION_INFO="{corpus_name}/transcription-info.bed"
   

def get_feature_config(wildcards):
    c = config['features'][wildcards.feature_name]
    c['window_size'] = config['window_size']
    return c

def get_download_filename(feature_name, idx):
    feature_config = config['features'][feature_name]
    url=feature_config['url'][idx]

    if url=='$transcription':
        return TRANSCRIPTION_INFO
    elif urlparse(url).scheme in ('http', 'https',):
        return  f'{{corpus_name}}/downloads/{feature_name}.{idx}.out'
    else:
        return url


def get_ingestion_input_filename(feature_name):
    feature_config = config['features'][feature_name]
    url=feature_config['url']
    needs_processing = not feature_config['processing_fn'] == 'none'
    if len(url) > 1 and not needs_processing:
        raise ValueError(f"Multiple URLs for feature {feature_name} but no processing function specified")
    
    is_url = urlparse(url[0]).scheme in ('http', 'https',)
    if needs_processing:
        return f'{{corpus_name}}/processed/{feature_name}.out'
    elif is_url:
        return f'{{corpus_name}}/downloads/{feature_name}.0.out'
    else:
        return url[0]


rule all:   
    input: f'{config["corpus_name"]}/DONE.txt'

rule collect:
    input:
        [f"{{corpus_name}}/.added_features/{feature_name}.txt" for feature_name in config['features'].keys() if not config['features'][feature_name]['skip']] + \
        [f"{{corpus_name}}/.added_samples/{sample_name}.txt" for sample_name in config['samples'].keys()]
    output:
        touch("{corpus_name}/DONE.txt")

rule test_submission:
    output: 'test.submission.txt'
    conda: 'locusregression'
    resources:
        mem_mb=500,
        runtime=5
    shell:
        'echo "Success!" > {output}'

rule download_gene_quant:
    output:
        temp("{corpus_name}/downloads/gene_quantification.bed")
    params:
        url=config['transcription']
    resources:
        mem_mb=512,
        runtime=60
    threads: 1
    shell:
        """
        wget -O {output} {params.url}
        """

rule join_gene_quant:
    input:
        rules.download_gene_quant.output
    output:
        temp(TRANSCRIPTION_INFO)
    params:
        gene_annotation=config['gene_annotation']
    resources:
        mem_mb=1000,
        runtime=30
    threads: 1
    conda: "locusregression"
    shell:
        '''
        get_gene_features.py \
            -genes {params.gene_annotation} \
            -quant {input} \
            --output {output}
        '''


rule download_resource:
    output:
        temp("{corpus_name}/downloads/{feature_name}.{idx}.out")
    params:
        url=lambda w : get_feature_config(w)['url'][int(w.idx)]
    resources:
        mem_mb=512,
        runtime=60
    threads: 1
    log: '{corpus_name}/logs/download_resource/{feature_name}.{idx}.log'
    shell:
        """
        wget -O {output} {params.url} 2> {log}
        """


def get_features_for_making_windows(wilcards):
    return [
        get_ingestion_input_filename(feature_name) 
        for feature_name, feature_config in config['features'].items()
        if ('affects_windows' in feature_config and feature_config['affects_windows']) \
            or (feature_config['type'] in ('categorical', 'cardinality') and not 'affects_windows' in feature_config)
    ]

rule get_regions:
    input:
        categorical_features=get_features_for_making_windows,
        chromsizes=config['chromsizes'],
        blacklist=config['blacklist']
    output:
        regions=REGIONS_NAME,
        report='{corpus_name}/regions_report.txt',
    params:
        window_size=config['window_size'],
    resources:
        mem_mb=scale_by_attempt(10000),
        runtime=scale_by_attempt(60)
    threads: 1
    conda: "locusregression"
    log: '{corpus_name}/logs/get_regions.log'
    shell:
        """
        locusregression get-regions \
            --window-size {params.window_size} \
            --blacklist-file {input.blacklist} \
            --genome-file {input.chromsizes} \
            --categorical-features {input.categorical_features} \
            --output {output.regions} 2> {log} > {output.report}
        """


rule make_fake_windows:
    output:
        touch(".fakewindows.bed")

def get_process_input(wildcards):
    f = get_feature_config(wildcards)
    input_args=[]
    if f['type'] in ('categorical', 'cardinality'):
        input_args.append('.fakewindows.bed')
    else:
        input_args.append(rules.get_regions.output.regions)
    
    for idx in range(len(f['url'])):
        input_args.append( get_download_filename(wildcards.feature_name,idx) )

    return input_args
        

def get_conda_envname(w):
    envname=get_feature_config(w)['conda']
    if envname.startswith('envs/'):
        return os.path.join(config['_snakepath'], envname)
    
    return envname


def get_process_mem_mb(wildcards, attempt):
    num_input=len(get_process_input(wildcards))-1
    return get_feature_config(wildcards)['mem_mb']*num_input*attempt

def get_process_runtime(wildcards, attempt):
    return get_feature_config(wildcards)['runtime']*attempt


rule process_resource:
    input:
        get_process_input
    output:
        "{corpus_name}/processed/{feature_name}.out"
    params:
        processing_fn=lambda w : get_feature_config(w)['processing_fn'],
    resources:
        mem_mb=get_process_mem_mb,
        runtime=get_process_runtime,
    threads: 1
    conda: get_conda_envname
    log: '{corpus_name}/logs/process_resource/{feature_name}.log'
    shell:
        """
        {params.processing_fn} {output} {input} 2> {log}
        """

rule create_corpus:
    input:
        regions=rules.get_regions.output.regions,
    output:
        corpus=CORPUS_NAME
    params:
        fasta=config['fasta'],
        dtype=config['dtype'],
        corpus_name=config['corpus_name'],
        extra_params=config['extra_params'],
    resources:
        mem_mb=scale_by_attempt(10000),
        runtime=scale_by_attempt(60),
    threads: 1
    conda: "locusregression"
    log: '{corpus_name}/logs/create_corpus.log'
    shell:
        """
        locusregression corpus-create \
            {output} \
            --corpus-name {params.corpus_name} \
            --fasta-file {params.fasta} \
            --dtype {params.dtype} \
            --regions-file {input.regions} \
            {params.extra_params} 2> {log}
        """

def get_ingestion_params(wildcards):
    feature_config = get_feature_config(wildcards)
    
    paramstr = ' '.join([
        f"--{k.replace('_', '-')} {v}"
        for k, v in feature_config.items()
        if k in FEATURE_TYPE_PARAMS[feature_config['type']]
    ])
    
    if feature_config['type']=='bedgraph':
        paramstr+=' --genome-file ' + config['chromsizes']
    
    if feature_config['type'] in ('bedgraph','bigwig'):
        paramstr+=' --extend ' + str(config['window_size']//2)

    return paramstr


rule ingest_feature:
    input:
        corpus=ancient(CORPUS_NAME),
        file=lambda w : get_ingestion_input_filename(w.feature_name),
    output:
        touch("{corpus_name}/.added_features/{feature_name}.txt")
    params:
        extra_params=get_ingestion_params,
        type=lambda w : get_feature_config(w)['type'],
    resources:
        mem_mb=scale_by_attempt(5000),
        runtime=scale_by_attempt(60),
    threads: 1
    conda: "locusregression"
    log: '{corpus_name}/logs/ingest_feature/{feature_name}.log'
    shell:
        """
        locusregression corpus-ingest-{params.type} \
            {input.corpus} \
            {input.file} \
            --feature-name {wildcards.feature_name} \
            {params.extra_params} 2> {log}
        """

mutrate_filename=CORPUS_NAME + '.mutrate.bedgraph'
rule get_background_mutrate:
    input:
        samples=[filename for filename in config['samples'].values()],
        chromsizes=config['chromsizes'],
    output:
        temp(mutrate_filename)
    params:
        chr_prefix=config['chr_prefix']
    resources:
        mem_mb=2000,
        runtime=30,
    threads: 1
    conda: "locusregression"
    log: '{corpus_name}/logs/get_background_mutrate.log'
    shell:
        """
        locusregression preprocess-estimate-mutrate \
            -vcfs {input.samples} \
            --chr-prefix {params.chr_prefix} \
            --genome-file {input.chromsizes} \
            --output {output} 2> {log}
        """

def get_sample_filename(wildcards):
    return config['samples'][wildcards.sample_name]

def get_sample_group(wildcards, num_per_group=50):
    return f"samples.{list(config['samples'].keys()).index(wildcards.sample_name) // num_per_group}"

rule ingest_sample:
    input:
        corpus=ancient(CORPUS_NAME),
        sample_file=get_sample_filename,
        fasta=config['fasta'],
        background_mutation_rate=lambda w : CORPUS_NAME + '.mutrate.bedgraph',
    output:
        temp("{corpus_name}/.added_samples/{sample_name}.txt")
    params:
        chr_prefix=config['chr_prefix'],
        weight_col='--weight-col ' + config['weight_col'] if 'weight_col' in config else '',
    group:
        get_sample_group
    resources:
        mem_mb=scale_by_attempt(1000),
        runtime=scale_by_attempt(5),
    threads: 1
    conda: "locusregression"
    log: '{corpus_name}/logs/ingest_sample/{sample_name}.log'
    shell:
        """
        locusregression corpus-ingest-sample \
            {input.corpus} \
            {input.sample_file} \
            --sample-name {wildcards.sample_name} \
            --mutation-rate-bedgraph {input.background_mutation_rate} \
            {params.weight_col} -fa {input.fasta} 2> {log}
        """
