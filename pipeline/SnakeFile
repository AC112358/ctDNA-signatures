from snakemake.utils import validate
from urllib.parse import urlparse
import os
from functools import partial

wildcard_constraints:
    feature_name="[a-zA-Z0-9_]+",
    idx="[0-9]+",

#configfile: "config.yaml"
validate(config, 'config.schema.yaml')

CORPUS_NAME=f"corpus.{config['corpus_name']}.h5"
REGIONS_NAME=f"{config['corpus_name']}/regions.{config['corpus_name']}.bed"
FEATURE_TYPE_PARAMS = {
    'bigwig' : ['normalization', 'extend', 'group'],
    'bedgraph' : ['normalization', 'extend', 'group'],
    'distance' : ['normalization', 'group'],
    'categorical' : ['null_value', 'column', 'group'],
    'vector' : ['normalization', 'group'],
    'cardinality' : ['column'],
}

def get_feature_config(wildcards):
    c = config['features'][wildcards.feature_name]
    c['window_size'] = config['window_size']
    return c

def get_download_filename(feature_name, idx):
    feature_config = config['features'][feature_name]
    url=feature_config['url'][idx]
    if urlparse(url).scheme in ('http', 'https',):
        return  f'{config["corpus_name"]}/downloads/{feature_name}.{idx}.out'
    else:
        return url


def get_ingestion_input_filename(feature_name):
    feature_config = config['features'][feature_name]
    url=feature_config['url']
    needs_processing = not feature_config['processing_fn'] == 'none'
    if len(url) > 1 and not needs_processing:
        raise ValueError(f"Multiple URLs for feature {feature_name} but no processing function specified")
    
    is_url = urlparse(url[0]).scheme in ('http', 'https',)
    if needs_processing:
        return f'{config["corpus_name"]}/processed/{feature_name}.out'
    elif is_url:
        return f'{config["corpus_name"]}/downloads/{feature_name}.0.out'
    else:
        return url[0]


rule all:
    input:
        [f"{config['corpus_name']}/.added_features/{feature_name}.txt" for feature_name in config['features'].keys() if not config['features'][feature_name]['skip']] + \
        [f"{config['corpus_name']}/.added_samples/{sample_name}.txt" for sample_name in config['samples'].keys()]


rule download_resource:
    output:
        temp(config['corpus_name'] + "/downloads/{feature_name}.{idx}.out")
    params:
        url=lambda w : get_feature_config(w)['url'][int(w.idx)]
    resources:
        mem_mb=512,
        runtime=60
    threads: 1
    shell:
        """
        wget -O {output} {params.url}
        """


def get_features_for_making_windows(wilcards):
    return [
        get_ingestion_input_filename(feature_name) 
        for feature_name, feature_config in config['features'].items()
        if ('affects_windows' in feature_config and feature_config['affects_windows']) \
            or (feature_config['type'] in ('categorical', 'cardinality') and not 'affects_windows' in feature_config)
    ]

rule get_regions:
    input:
        categorical_features=get_features_for_making_windows,
        chromsizes=config['chromsizes'],
        blacklist=config['blacklist']
    output:
        regions=REGIONS_NAME
    params:
        window_size=config['window_size'],
    resources:
        mem_mb=10000,
        runtime=30
    threads: 1
    conda: "locusregression"
    shell:
        """
        locusregression get-regions \
            --window-size {params.window_size} \
            --blacklist-file {input.blacklist} \
            --genome-file {input.chromsizes} \
            --categorical-features {input.categorical_features} \
            --output {output}
        """    


rule make_fake_windows:
    output:
        touch(".fakewindows.bed")

def get_process_input(wildcards):
    f = get_feature_config(wildcards)
    input_args=[]
    if f['type'] in ('categorical', 'cardinality'):
        input_args.append('.fakewindows.bed')
    else:
        input_args.append(rules.get_regions.output.regions)
    
    for idx in range(len(f['url'])):
        input_args.append( get_download_filename(wildcards.feature_name,idx) )

    return input_args
        

rule process_resource:
    input:
        get_process_input
    output:
        temp(config['corpus_name'] + "/processed/{feature_name}.out")
    params:
        processing_fn=lambda w : get_feature_config(w)['processing_fn'],
    resources:
        mem_mb=5000,
        runtime=30,
    threads: 1
    conda: "locusregression"
    shell:
        """
        {params.processing_fn} {output} {input}
        """

rule create_corpus:
    input:
        regions=rules.get_regions.output.regions,
    output:
        corpus=CORPUS_NAME
    params:
        fasta=config['fasta'],
        dtype=config['dtype'],
        corpus_name=config['corpus_name'],
        extra_params=config['extra_params'],
    resources:
        mem_mb=3000,
        runtime=60,
    threads: 1
    conda: "locusregression"
    shell:
        """
        locusregression corpus-create \
            {output} \
            --corpus-name {params.corpus_name} \
            --fasta-file {params.fasta} \
            --dtype {params.dtype} \
            --regions-file {input.regions} \
            {params.extra_params}
        """

def get_ingestion_params(wildcards):
    feature_config = get_feature_config(wildcards)
    paramstr = ' '.join([
        f"--{k.replace('_', '-')} {v}"
        for k, v in feature_config.items()
        if k in FEATURE_TYPE_PARAMS[feature_config['type']]
    ])
    if feature_config['type']=='bedgraph':
        paramstr+=' --genome-file ' + config['chromsizes']
    return paramstr


rule ingest_feature:
    input:
        corpus=ancient(CORPUS_NAME),
        file=lambda w : get_ingestion_input_filename(w.feature_name),
    output:
        touch(config['corpus_name'] + "/.added_features/{feature_name}.txt")
    params:
        extra_params=get_ingestion_params,
        type=lambda w : get_feature_config(w)['type'],
    resources:
        mem_mb=5000,
        runtime=15,
    threads: 1
    conda: "locusregression"
    shell:
        """
        locusregression corpus-ingest-{params.type} \
            {input.corpus} \
            {input.file} \
            --feature-name {wildcards.feature_name} \
            {params.extra_params} \
        """

mutrate_filename=CORPUS_NAME + '.mutrate.bedgraph'
rule get_background_mutrate:
    input:
        samples=[filename for filename in config['samples'].values()],
        chromsizes=config['chromsizes'],
    output:
        temp(mutrate_filename)
    params:
        chr_prefix=config['chr_prefix'],
    resources:
        mem_mb=2000,
        runtime=30,
    threads: 1
    conda: "locusregression"
    shell:
        """
        locusregression preprocess-estimate-mutrate \
            -vcfs {input.samples} \
            --chr-prefix {params.chr_prefix} \
            --genome-file {input.chromsizes} \
            --output {output}
        """

def get_sample_filename(wildcards):
    return config['samples'][wildcards.sample_name]

def get_sample_group(wildcards, num_per_group=50):
    return f"samples.{list(config['samples'].keys()).index(wildcards.sample_name) // num_per_group}"

rule ingest_sample:
    input:
        corpus=ancient(CORPUS_NAME),
        sample_file=get_sample_filename,
        fasta=config['fasta'],
        background_mutation_rate=lambda w : CORPUS_NAME + '.mutrate.bedgraph',
    output:
        temp(config['corpus_name'] + ".added_samples/{sample_name}.txt")
    params:
        weight_col=config['weight_col'],
    group:
        get_sample_group
    resources:
        mem_mb=1000,
        runtime=5,
    threads: 1
    conda: "locusregression"
    shell:
        """
        locusregression corpus-ingest-sample \
            {input.corpus} \
            {input.sample_file} \
            --sample-name {wildcards.sample_name} \
            --weight-col {params.weight_col} \
            --mutation-rate-bedgraph {input.background_mutation_rate} \
            -fa {input.fasta}
        """
